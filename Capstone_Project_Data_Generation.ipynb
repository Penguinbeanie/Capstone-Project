{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Penguinbeanie/Capstone-Project/blob/dev_branch/Capstone_Project_Data_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Model"
      ],
      "metadata": {
        "id": "cv0Pr_-GUxdi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP43IcWEagqd"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "# retrieving the key stored in Colab\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# configure the key for calling GenAI model\n",
        "genai.configure(api_key=key)\n",
        "\n",
        "# load model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting Original Questionnaire Questions by Question Type"
      ],
      "metadata": {
        "id": "LdNtU4F5U2QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "input_files = [\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire1.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire2.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire3.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire4.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire5.json\"\n",
        "]\n",
        "\n",
        "# Dictionary to hold questions grouped by type\n",
        "question_types = {}\n",
        "\n",
        "# Iterate through each file\n",
        "for file_url in input_files:\n",
        "    response = requests.get(file_url)\n",
        "    data = response.json()\n",
        "    for entry in data:\n",
        "        q_type = entry['type']\n",
        "        if q_type not in question_types:\n",
        "            question_types[q_type] = []\n",
        "        question_types[q_type].append(entry)\n",
        "\n",
        "# Save each question type to separate JSON files\n",
        "output_files = []\n",
        "for q_type, questions in question_types.items():\n",
        "    filename = f\"/content/{q_type}.json\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(questions, f, indent=4)\n",
        "    output_files.append(filename)\n",
        "\n",
        "print(\"Files have been created.\")\n"
      ],
      "metadata": {
        "id": "qbMOX-eeOmDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON To String For Context"
      ],
      "metadata": {
        "id": "fzkGkBZ_VBfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load files\n",
        "\n",
        "import json\n",
        "import requests\n",
        "\n",
        "file_path_date = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/DATE.json'\n",
        "file_path_multi = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/MULTI_SELECT.json'\n",
        "file_path_number = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/NUMBER.json'\n",
        "file_path_single = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/SINGLE_SELECT.json'\n",
        "file_path_text = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/TEXT.json'\n",
        "\n",
        "# Function to load JSON from URL\n",
        "def load_json_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "    return response.json()\n",
        "\n",
        "# Load JSON data from URLs\n",
        "try:\n",
        "    json_data_date = load_json_from_url(file_path_date)\n",
        "    json_data_multi = load_json_from_url(file_path_multi)\n",
        "    json_data_number = load_json_from_url(file_path_number)\n",
        "    json_data_single = load_json_from_url(file_path_single)\n",
        "    json_data_text = load_json_from_url(file_path_text)\n",
        "\n",
        "    # Convert JSON data to strings (if needed)\n",
        "    json_string_date = json.dumps(json_data_date, indent=4)\n",
        "    json_string_multi = json.dumps(json_data_multi, indent=4)\n",
        "    json_string_number = json.dumps(json_data_number, indent=4)\n",
        "    json_string_single = json.dumps(json_data_single, indent=4)\n",
        "    json_string_text = json.dumps(json_data_text, indent=4)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error loading JSON files: {e}\")\n"
      ],
      "metadata": {
        "id": "J63VsTV7dEyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Model"
      ],
      "metadata": {
        "id": "SWiAL7IBVM45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "\n",
        "multiVar = 10\n",
        "singleVar = 10\n",
        "numberVar = 50\n",
        "textVar = 50\n",
        "dateVar = 50\n",
        "\n",
        "prompt_multi = f\"\"\"\n",
        "                Using the context below as a template, create {multiVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"MULTI-SELECT\". The \"options\" array should contain multiple unique objects,\n",
        "                each with the \"option\" key and a meaningful value representing an available choice. No IDs should be included.\n",
        "                Generate multiple unique examples of questions that make sense in context for the type \"MULTI-SELECT\".\n",
        "                Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Diverse.\n",
        "\n",
        "                Context:\n",
        "                {json_string_multi}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_single = f\"\"\"\n",
        "                Using the context below as a template, create {singleVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"SINGLE-SELECT\". The \"options\" array should contain multiple unique objects,\n",
        "                each with the \"option\" key and a meaningful value representing an available choice. No IDs should be included.\n",
        "                Generate multiple unique examples of questions that make sense in context for the type \"SINGLE-SELECT\".\n",
        "                Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Communications.\n",
        "\n",
        "                Context:\n",
        "                {json_string_single}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_text = f\"\"\"\n",
        "                Using the context below as a template, create {textVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"TEXT\", the \"options\" array always contains exactly one object with\n",
        "                the \"option\" set to \"Text\", and no IDs are included. Generate multiple unique examples of questions that make sense in context\n",
        "                for the type \"TEXT\". They should be open ended. Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Communications. (General topic in the field of communications, not directly the word communications)\n",
        "\n",
        "                Context:\n",
        "                {json_string_text}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_number = f\"\"\"\n",
        "                Using the context below as a template, create {numberVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"NUMBER\", the \"options\" array always contains exactly one object with\n",
        "                the \"option\" set to the category the question best, and no IDs are included. Generate multiple unique examples of questions that make sense in context\n",
        "                for the type \"NUMBER\". Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Convention/Fair.\n",
        "\n",
        "                Context:\n",
        "                {json_string_number}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_date = f\"\"\"\n",
        "                Using the context below as a template, create {dateVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"DATE\", the \"options\" array always contains exactly one object with\n",
        "                the \"option\" set to \"Date\", and no IDs are included. Generate multiple unique examples of questions that make sense in context\n",
        "                for the type \"DATE\". Make sure the question specifically ask for a date. Add \"Provide a date.\" at the end of each question.\n",
        "                Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Healthcare.\n",
        "\n",
        "                Context:\n",
        "                {json_string_date}\n",
        "                \"\"\"\n",
        "\n",
        "\n",
        "# responses\n",
        "responses = {\n",
        "    #\"prompt_multi\": \"Questionnaire_Multi_Artificial.json\",\n",
        "    #\"prompt_single\": \"Questionnaire_Single_Artificial.json\",\n",
        "    #\"prompt_date\": \"Questionnaire_Date_Artificial.json\",\n",
        "    #\"prompt_number\": \"Questionnaire_Number_Artificial.json\",\n",
        "    \"prompt_text\": \"Questionnaire_Text_Artificial.json\"\n",
        "}\n",
        "\n",
        "for response_name, response_file in responses.items():\n",
        "    prompt = globals()[response_name]  # Get the prompt string\n",
        "    response = model.generate_content(prompt)  # Get model's response\n",
        "\n",
        "    try:\n",
        "        response_data = json.loads(response.text)  # Parse the response text as JSON\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON for {response_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Write the parsed JSON to a file\n",
        "    with open(response_file, \"w\") as json_file:\n",
        "        json.dump(response_data, json_file, indent=4)\n",
        "\n",
        "    print(f\"JSON file '{response_file}' has been created\")"
      ],
      "metadata": {
        "id": "sxSLA1-SbAG3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#JSON to Dataframe"
      ],
      "metadata": {
        "id": "xoc_3zsxUd6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MULTI"
      ],
      "metadata": {
        "id": "1E1TXueCdKw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_Diverse.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_HeavyIndustry.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_Sales.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_SoftwareDev.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_MULTI = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_MULTI.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('MULTI_combined.csv', index=False)\n",
        "\n",
        "df_MULTI"
      ],
      "metadata": {
        "id": "harKmP4IUdgZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SINGLE"
      ],
      "metadata": {
        "id": "fF6N95AP2eJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_ArtIndustry.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_Communications.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_Diverse.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_SoftwareDev.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_SINGLE = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_SINGLE.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('SINGLE_combined.csv', index=False)\n",
        "\n",
        "df_SINGLE\n"
      ],
      "metadata": {
        "id": "9fA2yR_k2f2Y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NUMBER"
      ],
      "metadata": {
        "id": "_PF7TsoUGzVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_BusinessAndJob.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_HeavyIndustries.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_Diverse.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_Customer.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_NUMBER = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_NUMBER.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('NUMBER_combined.csv', index=False)\n",
        "\n",
        "df_NUMBER"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ymm1w1W-FLfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATE"
      ],
      "metadata": {
        "id": "fknbAzNquMPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_Customer.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_HeavyIndustries.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_Technology.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_Healthcare.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_DATE = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_DATE.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('DATE_combined.csv', index=False)\n",
        "\n",
        "df_DATE"
      ],
      "metadata": {
        "id": "pOMExV7LuSKa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT"
      ],
      "metadata": {
        "id": "7HtP3UXQa6zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_Communications.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_HeavyIndustries.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_CustomerSupport.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_Convention.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_TEXT = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_TEXT.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('TEXT_combined.csv', index=False)\n",
        "\n",
        "df_TEXT"
      ],
      "metadata": {
        "id": "PuXWkq5Ga8nr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer Generation"
      ],
      "metadata": {
        "id": "jYs5pcRiHA45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MULTI"
      ],
      "metadata": {
        "id": "IJu2V5dNOlMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_MULTI_with_answers = df_MULTI.iloc[100:190].copy()\n",
        "\n",
        "# Generate a single compact prompt for all variations\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {', '.join(row['options'])}\n",
        "\n",
        "            Provide 5 different responses to this multiple choice question. Each response should select from the given options. Chose a different\n",
        "            cobination of options (or single option) for each response. Each answer (V, C, Q, E, A) is to be given by a seperate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain the options corresponding to the response.\n",
        "            Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [options corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [options corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [options corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [options corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [options corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "# Parse the response text into separate variations\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Extract each response type\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            # Find the line starting with this prefix\n",
        "            response_line = next((line for line in lines if line.strip().startswith(prefix)), '')\n",
        "            # Remove the prefix and trim\n",
        "            response = response_line.replace(prefix, '', 1).strip()\n",
        "            answers[f\"answer_{key}\"] = response if response else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "            answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "# Process a single row with retries\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "# Process the dataframe\n",
        "answer_columns = df_MULTI_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "# Add columns to dataframe\n",
        "for key in prefixes:\n",
        "    df_MULTI_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "# Save to CSV\n",
        "df_for_csv_MULTI_answer = df_MULTI_with_answers.copy()\n",
        "df_for_csv_MULTI_answer['options'] = df_for_csv_MULTI_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_MULTI_answer.to_csv('MULTI_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_MULTI_with_answers"
      ],
      "metadata": {
        "id": "7HnQEYdTcWJl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0_100 = pd.read_csv('MULTI_answer_combined_0-100.csv', sep = '>')\n",
        "df_101_189 = pd.read_csv('MULTI_answer_combined_101-189.csv', sep = '>')\n",
        "\n",
        "df_MULTI_with_answers_total = pd.concat([df_0_100, df_101_189], ignore_index=True)\n",
        "df_MULTI_with_answers_total.to_csv('MULTI_answer_combined_total.csv', index=False, sep='>')\n"
      ],
      "metadata": {
        "id": "sZGCWwgNPZ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_MULTI_with_answers_total.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_MULTI = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_MULTI.to_csv('MULTI_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_MULTI\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hmW2i6BgUohp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SINGLE"
      ],
      "metadata": {
        "id": "EjMmZuD9gntG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_SINGLE_with_answers = df_SINGLE.iloc[101:150].copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {', '.join(row['options'])}\n",
        "            Provide 5 different responses to this single choice question. Each response should select from the given options. Chose a different\n",
        "            option for each response (if enough options exist for all 5 responses, otherwise repeat options after having already used all of them).\n",
        "            Each answer (V, C, Q, E, A) is to be given by a seperate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain the option corresponding to the response. Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [option corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [option corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [option corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [option corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [option corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_SINGLE_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "# Add columns to dataframe\n",
        "for key in prefixes:\n",
        "    df_SINGLE_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_SINGLE_answer = df_SINGLE_with_answers.copy()\n",
        "df_for_csv_SINGLE_answer['options'] = df_for_csv_SINGLE_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_SINGLE_answer.to_csv('SINGLE_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_SINGLE_with_answers"
      ],
      "metadata": {
        "id": "1lfnfIlMKer7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0_100 = pd.read_csv('SINGLE_answer_combined_0-100.csv', sep = '>')\n",
        "df_101_189 = pd.read_csv('SINGLE_answer_combined_101-149.csv', sep = '>')\n",
        "\n",
        "df_SINGLE_with_answers_total = pd.concat([df_0_100, df_101_189], ignore_index=True)\n",
        "df_SINGLE_with_answers_total.to_csv('SINGLE_answer_combined_total.csv', index=False, sep='>')"
      ],
      "metadata": {
        "id": "GHnb9QaWWIj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_SINGLE_with_answers_total.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_SINGLE = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_SINGLE.to_csv('SINGLE_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_SINGLE"
      ],
      "metadata": {
        "collapsed": true,
        "id": "58o5474EWVXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NUMBER"
      ],
      "metadata": {
        "id": "0ise3ICagtyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_NUMBER_with_answers = df_NUMBER.copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {row['options']}\n",
        "            Provide 5 different responses to this single choice question, which asks for a number. The question provides a single option defining the type of number to be chosen.\n",
        "            Each response should adhere to the given type but provide a unique answer. Some answers should be written as numbers, some such that the numbers are spelled out.\n",
        "            Each answer (V, C, Q, E, A) is to be given by a separate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain just the number (with correct units) corresponding to the response. Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [number corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [number corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [number corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [number corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [number corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_NUMBER_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "for key in prefixes:\n",
        "    df_NUMBER_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_NUMBER_answer = df_NUMBER_with_answers.copy()\n",
        "df_for_csv_NUMBER_answer['options'] = df_for_csv_NUMBER_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_NUMBER_answer.to_csv('NUMBER_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_NUMBER_with_answers"
      ],
      "metadata": {
        "id": "aU9ROXGkgtcP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert options to strings before melting\n",
        "df_NUMBER_with_answers['options'] = df_NUMBER_with_answers['options'].astype(str)\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_NUMBER_with_answers.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_NUMBER = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_NUMBER.to_csv('NUMBER_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_NUMBER"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rYk5P-mpdlb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATE"
      ],
      "metadata": {
        "id": "ECZEWIdvu1c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_DATE_with_answers = df_DATE.copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {row['options']}\n",
        "            Provide 5 different responses to this single choice question, which asks for a date. The question provides one option defining the type to be chosen.\n",
        "            Each response should adhere to the given type but provide a unique answer. Some answers should be written as numbers, some such that the numbers are spelled out. Use different date formats.\n",
        "            Assume question takers are from Europe.\n",
        "            Each answer (V, C, Q, E, A) is to be given by a separate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain just the date corresponding to the response. Use this date format: dd-mm-yyyy and nothing else for the label.\n",
        "            Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [date corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [date corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [date corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [date corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [date corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_DATE_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "for key in prefixes:\n",
        "    df_DATE_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_DATE_answer = df_DATE_with_answers.copy()\n",
        "df_for_csv_DATE_answer['options'] = df_for_csv_DATE_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_DATE_answer.to_csv('DATE_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_DATE_with_answers"
      ],
      "metadata": {
        "id": "iXfSbksBu5ZP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert options to strings before melting\n",
        "df_DATE_with_answers['options'] = df_DATE_with_answers['options'].astype(str)\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_DATE_with_answers.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_DATE = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_DATE.to_csv('DATE_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_DATE"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sdK6AoV2kX6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT"
      ],
      "metadata": {
        "id": "eo-6wzxObq_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_TEXT_with_answers = df_TEXT.copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {row['options']}\n",
        "            Provide 5 different responses to this single choice question, which asks for a text. The question provides a single option defining the type of answer to be chosen.\n",
        "            Each response should adhere to the given type but provide a unique answer. The questions are open ended, therfore your answer should replicate a human's answer to such a question.\n",
        "            Each answer (V, C, Q, E, A) is to be given by a separate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain the shortest possible topic summery.\n",
        "            Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [summery corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [summery corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [summery corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [summery corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [summery corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_TEXT_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "for key in prefixes:\n",
        "    df_TEXT_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_TEXT_answer = df_TEXT_with_answers.copy()\n",
        "df_for_csv_TEXT_answer['options'] = df_for_csv_TEXT_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_TEXT_answer.to_csv('TEXT_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_TEXT_with_answers"
      ],
      "metadata": {
        "id": "gHv02WL_bsZ7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert options to strings before melting\n",
        "df_TEXT_with_answers['options'] = df_TEXT_with_answers['options'].astype(str)\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_TEXT_with_answers.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_TEXT = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_TEXT.to_csv('TEXT_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_TEXT"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8oh-H7Ppkjy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge all CSV Files"
      ],
      "metadata": {
        "id": "fpllBNgP4lnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# list all csv files only\n",
        "csv_files = ['TEXT_answer_combined_total_reshaped.csv', 'DATE_answer_combined_total_reshaped.csv', 'NUMBER_answer_combined_total_reshaped.csv', 'SINGLE_answer_combined_total_reshaped.csv', 'MULTI_answer_combined_total_reshaped.csv']\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create an empty list to store each DataFrame\n",
        "dfs = []\n",
        "\n",
        "# Read each CSV file and append to the list\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file, sep='>')\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV\n",
        "merged_df.to_csv('all_answers_combined_reshaped.csv', index=False, sep='>')\n"
      ],
      "metadata": {
        "id": "3gPayKx5r-MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv('all_answers_combined_reshaped.csv', sep='>')\n",
        "df_all"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EL7_TQMzsorm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['options'] = df_all['options'].str.replace(r\"\\['|'\\]\", \"\", regex=True)"
      ],
      "metadata": {
        "id": "uR_rbnNdvV18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.to_csv('all_answers_combined_reshaped.csv', index=False, sep='>')"
      ],
      "metadata": {
        "id": "86ZLZ9PYvgg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Up CSV"
      ],
      "metadata": {
        "id": "27qOi2nti_bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all rows containing quotation marks\n",
        "\n",
        "import csv\n",
        "import requests\n",
        "\n",
        "def clean_csv_from_github(url, output_file):\n",
        "    \"\"\"\n",
        "    Reads a CSV file from a GitHub raw URL, removes rows containing quotation marks,\n",
        "    and saves the cleaned data to a new CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): The GitHub raw URL of the CSV file.\n",
        "        output_file (str): The file path to save the cleaned CSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fetch the CSV content from the GitHub raw URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "\n",
        "        # Decode the content and split into lines\n",
        "        csv_content = response.text\n",
        "        csv_lines = csv_content.splitlines()\n",
        "\n",
        "        # Read the CSV into memory\n",
        "        reader = csv.reader(csv_lines, delimiter='>')\n",
        "        cleaned_rows = []\n",
        "\n",
        "        for row in reader:\n",
        "            # Remove rows containing quotation marks\n",
        "            if not any('\"' in field for field in row):\n",
        "                corrected_row = [field.replace('MULTI_SELECT', 'MULTI-SELECT').replace('SINGLE_SELECT', 'SINGLE-SELECT') for field in row]\n",
        "                cleaned_rows.append(corrected_row)\n",
        "\n",
        "\n",
        "\n",
        "        # Write the cleaned rows to a new CSV file\n",
        "        with open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
        "            writer = csv.writer(outfile, delimiter='>')\n",
        "            writer.writerows(cleaned_rows)\n",
        "\n",
        "        print(f\"Cleaned CSV saved to {output_file}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching the CSV file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_answers/all_answers_combined_reshaped.csv'\n",
        "output_file = 'cleaned_all_answers_combined_reshaped_type_adjusted.csv'\n",
        "clean_csv_from_github(url, output_file)"
      ],
      "metadata": {
        "id": "YyZdvoVCjDsc",
        "outputId": "6dac24dd-c18e-4fe4-b766-19d7ff3a005b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned CSV saved to cleaned_all_answers_combined_reshaped_type_adjusted.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Additional Labels"
      ],
      "metadata": {
        "id": "G8MTiEvrki5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MULTI AND SINGLE"
      ],
      "metadata": {
        "id": "1UDpA0EdsP3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "\n",
        "def load_csv_method1(url):\n",
        "    df = pd.read_csv(url, sep='>', names=['type', 'question', 'options', 'answer', 'answer_label_GEMINI', 'answer_category'], converters={'options': lambda x: x.split(';')})\n",
        "    return df\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_answers/cleaned_all_answers_combined_reshaped_type_adjusted.csv'\n",
        "df_full = load_csv_method1(url)\n",
        "\n",
        "df_MULTI_full = df_full[df_full['type'] == 'MULTI-SELECT']\n",
        "df_MULTI = df_MULTI_full.copy()\n",
        "\n",
        "df_SINGLE_full = df_full[df_full['type'] == 'SINGLE-SELECT']\n",
        "df_SINGLE = df_SINGLE_full.copy().head(10)\n",
        "\n",
        "print(df_MULTI)\n",
        "\n",
        "# Process MULTI-SELECT in batches with exception handling\n",
        "def classify_multi(df):\n",
        "    answers = df[\"answer\"].tolist()\n",
        "    options = df[\"options\"].tolist()\n",
        "\n",
        "    results = []\n",
        "    for answer, option in zip(answers, options):\n",
        "        try:\n",
        "            result = classifier(answer, candidate_labels=option, multi_label=True)\n",
        "            # Filter labels with scores > 0.5\n",
        "            filtered = [label for label, score in zip(result[\"labels\"], result[\"scores\"]) if score > 0.5]\n",
        "        except Exception as e:\n",
        "            print(f\"Error classifying row with answer='{answer}' and options='{option}': {e}\")\n",
        "            filtered = []  # Return an empty list for rows with errors\n",
        "        results.append(filtered)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Process SINGLE-SELECT in batches with exception handling\n",
        "def classify_single(df):\n",
        "    answers = df[\"answer\"].tolist()\n",
        "    options = df[\"options\"].tolist()\n",
        "\n",
        "    results = []\n",
        "    for answer, option in zip(answers, options):\n",
        "        try:\n",
        "            result = classifier(answer, candidate_labels=option, multi_label=False)\n",
        "            selected_label = result[\"labels\"][0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error classifying row with answer='{answer}' and options='{option}': {e}\")\n",
        "            selected_label = None  # Return None for rows with errors\n",
        "        results.append(selected_label)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Apply the classification to each row\n",
        "\n",
        "df_MULTI[\"answer_label_BART_large_mnli\"] = classify_multi(df_MULTI)\n",
        "df_SINGLE[\"answer_label_BART_large_mnli\"] = classify_single(df_SINGLE)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_MULTI)\n",
        "print(df_SINGLE)\n",
        "\n",
        "# drop all rows where type == MULTI-SELECT\n",
        "df_full = df_full.drop(df_full[df_full['type'] == 'MULTI-SELECT'].index)\n",
        "df_full = df_full.drop(df_full[df_full['type'] == 'SINGLE-SELECT'].index)\n",
        "\n",
        "# append df_MULTI and df_SINGLE to df_full\n",
        "df_full = pd.concat([df_full, df_MULTI, df_SINGLE])\n",
        "df_full = df_full.sort_index()\n",
        "\n",
        "df_full.to_csv('all_answers_combined_reshaped_with_BART_large_mnli_MULTI_SINGLE_labels.csv', index=False, sep='>')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhfwJ2apV3X8",
        "outputId": "22248144-1dbb-4329-c4a0-b876b33c4676",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              type                                           question  \\\n",
            "3529  MULTI-SELECT             What algorithms are you familiar with?   \n",
            "3530  MULTI-SELECT             What algorithms are you familiar with?   \n",
            "3531  MULTI-SELECT             What algorithms are you familiar with?   \n",
            "3532  MULTI-SELECT             What algorithms are you familiar with?   \n",
            "3533  MULTI-SELECT             What algorithms are you familiar with?   \n",
            "...            ...                                                ...   \n",
            "4471  MULTI-SELECT  Which social media platforms do you use for ma...   \n",
            "4472  MULTI-SELECT  Which social media platforms do you use for ma...   \n",
            "4473  MULTI-SELECT  Which social media platforms do you use for ma...   \n",
            "4474  MULTI-SELECT  Which social media platforms do you use for ma...   \n",
            "4475  MULTI-SELECT  Which social media platforms do you use for ma...   \n",
            "\n",
            "                                                options  \\\n",
            "3529  [Sorting algorithms,  Searching algorithms,  G...   \n",
            "3530  [Sorting algorithms,  Searching algorithms,  G...   \n",
            "3531  [Sorting algorithms,  Searching algorithms,  G...   \n",
            "3532  [Sorting algorithms,  Searching algorithms,  G...   \n",
            "3533  [Sorting algorithms,  Searching algorithms,  G...   \n",
            "...                                                 ...   \n",
            "4471  [Facebook,  Instagram,  Twitter,  LinkedIn,  T...   \n",
            "4472  [Facebook,  Instagram,  Twitter,  LinkedIn,  T...   \n",
            "4473  [Facebook,  Instagram,  Twitter,  LinkedIn,  T...   \n",
            "4474  [Facebook,  Instagram,  Twitter,  LinkedIn,  T...   \n",
            "4475  [Facebook,  Instagram,  Twitter,  LinkedIn,  T...   \n",
            "\n",
            "                                                 answer  \\\n",
            "3529  I'm familiar with a wide range of algorithms, ...   \n",
            "3530          Sorting, searching, and graph algorithms.   \n",
            "3531  I know a bunch of those, like the sorting and ...   \n",
            "3532  My algorithm knowledge encompasses several cat...   \n",
            "3533  I know about sorting, searching, and divide an...   \n",
            "...                                                 ...   \n",
            "4471  We primarily utilize Facebook and Instagram fo...   \n",
            "4472                   Facebook, Instagram, and TikTok.   \n",
            "4473  We're all over Facebook and Insta, mostly.  Yo...   \n",
            "4474  Our marketing strategy uses a multi-platform a...   \n",
            "4475  We use Facebook, Instagram, and Twitter.  It's...   \n",
            "\n",
            "                                    answer_label_GEMINI answer_category  \n",
            "3529  [Sorting algorithms, Searching algorithms, Gra...         verbose  \n",
            "3530  [Sorting algorithms, Searching algorithms, Gra...         concise  \n",
            "3531  [Sorting algorithms, Searching algorithms, Gra...      colloquial  \n",
            "3532  [Sorting algorithms, Searching algorithms, Dyn...     explanatory  \n",
            "3533  [Sorting algorithms, Searching algorithms, Div...         annoyed  \n",
            "...                                                 ...             ...  \n",
            "4471                      Facebook, Instagram, LinkedIn         verbose  \n",
            "4472                        Facebook, Instagram, TikTok         concise  \n",
            "4473                       Facebook, Instagram, YouTube      colloquial  \n",
            "4474             Facebook, Instagram, YouTube, LinkedIn     explanatory  \n",
            "4475                       Facebook, Instagram, Twitter         annoyed  \n",
            "\n",
            "[947 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_full"
      ],
      "metadata": {
        "id": "AGanxhrkxN8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT"
      ],
      "metadata": {
        "id": "1ebDABsJsV9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_answers/all_answers_combined_reshaped_with_BART_large_mnli_MULTI_SINGLE_labels_fixed.txt'\n",
        "df_full = pd.read_csv(url, sep='>', header=0, names=['type', 'question', 'options', 'answer', 'answer_label_GEMINI', 'answer_category', 'answer_label_BART_large_mnli'])\n",
        "df_TEXT = df_full[df_full['type'] == 'TEXT']\n",
        "\n"
      ],
      "metadata": {
        "id": "Z_sSeFfpWJqT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    TokenClassificationPipeline,\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "from transformers.pipelines import AggregationStrategy\n",
        "import numpy as np\n",
        "\n",
        "# Define keyphrase extraction pipeline\n",
        "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
        "    def __init__(self, model, *args, **kwargs):\n",
        "        super().__init__(\n",
        "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
        "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def postprocess(self, all_outputs):\n",
        "        results = super().postprocess(\n",
        "            all_outputs=all_outputs,\n",
        "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
        "        )\n",
        "        return np.unique([result.get(\"word\").strip() for result in results])\n",
        "\n",
        "model_name = \"ml6team/keyphrase-extraction-distilbert-inspec\"\n",
        "extractor = KeyphraseExtractionPipeline(model=model_name)\n",
        "\n",
        "df_TEXT['keywords_distilbert'] = df_TEXT['answer'].apply(lambda x: extractor(x))\n",
        "df_TEXT['keywords_distilbert'] = df_TEXT['keywords_distilbert'].apply(lambda x: ', '.join(x))\n",
        "\n",
        "# drop all rows where type == TEXT\n",
        "df_full = df_full.drop(df_full[df_full['type'] == 'TEXT'].index)\n",
        "\n",
        "# append df_TEXT to df_full\n",
        "df_full = pd.concat([df_full, df_TEXT])\n",
        "df_full = df_full.sort_index()\n",
        "\n",
        "df_TEXT"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AsOemSmY6dpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full = df_full.fillna('NaN')\n",
        "df_full.to_csv('all_answers_combined_reshaped_with_BART_large_mnli_MULTI_SINGLE_TEXT_labels.csv', index=False, sep='>')\n",
        "df_full\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "60-FX0pk64l_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}