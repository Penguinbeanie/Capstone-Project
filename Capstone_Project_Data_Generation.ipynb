{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Penguinbeanie/Capstone-Project/blob/dev_branch/Capstone_Project_Data_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Model"
      ],
      "metadata": {
        "id": "cv0Pr_-GUxdi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xP43IcWEagqd"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "# retrieving the key stored in Colab\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# configure the key for calling GenAI model\n",
        "genai.configure(api_key=key)\n",
        "\n",
        "# load model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting Original Questionnaire Questions by Question Type"
      ],
      "metadata": {
        "id": "LdNtU4F5U2QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "input_files = [\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire1.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire2.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire3.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire4.json\",\n",
        "    \"https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/original_files/questionnaire5.json\"\n",
        "]\n",
        "\n",
        "# Dictionary to hold questions grouped by type\n",
        "question_types = {}\n",
        "\n",
        "# Iterate through each file\n",
        "for file_url in input_files:\n",
        "    response = requests.get(file_url)\n",
        "    data = response.json()\n",
        "    for entry in data:\n",
        "        q_type = entry['type']\n",
        "        if q_type not in question_types:\n",
        "            question_types[q_type] = []\n",
        "        question_types[q_type].append(entry)\n",
        "\n",
        "# Save each question type to separate JSON files\n",
        "output_files = []\n",
        "for q_type, questions in question_types.items():\n",
        "    filename = f\"/content/{q_type}.json\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(questions, f, indent=4)\n",
        "    output_files.append(filename)\n",
        "\n",
        "print(\"Files have been created.\")\n"
      ],
      "metadata": {
        "id": "qbMOX-eeOmDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON To String For Context"
      ],
      "metadata": {
        "id": "fzkGkBZ_VBfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load files\n",
        "\n",
        "import json\n",
        "import requests\n",
        "\n",
        "file_path_date = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/DATE.json'\n",
        "file_path_multi = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/MULTI_SELECT.json'\n",
        "file_path_number = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/NUMBER.json'\n",
        "file_path_single = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/SINGLE_SELECT.json'\n",
        "file_path_text = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/original_questionnaire/type_seperated/TEXT.json'\n",
        "\n",
        "# Function to load JSON from URL\n",
        "def load_json_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "    return response.json()\n",
        "\n",
        "# Load JSON data from URLs\n",
        "try:\n",
        "    json_data_date = load_json_from_url(file_path_date)\n",
        "    json_data_multi = load_json_from_url(file_path_multi)\n",
        "    json_data_number = load_json_from_url(file_path_number)\n",
        "    json_data_single = load_json_from_url(file_path_single)\n",
        "    json_data_text = load_json_from_url(file_path_text)\n",
        "\n",
        "    # Convert JSON data to strings (if needed)\n",
        "    json_string_date = json.dumps(json_data_date, indent=4)\n",
        "    json_string_multi = json.dumps(json_data_multi, indent=4)\n",
        "    json_string_number = json.dumps(json_data_number, indent=4)\n",
        "    json_string_single = json.dumps(json_data_single, indent=4)\n",
        "    json_string_text = json.dumps(json_data_text, indent=4)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error loading JSON files: {e}\")\n"
      ],
      "metadata": {
        "id": "J63VsTV7dEyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Model"
      ],
      "metadata": {
        "id": "SWiAL7IBVM45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "\n",
        "multiVar = 10\n",
        "singleVar = 10\n",
        "numberVar = 50\n",
        "textVar = 50\n",
        "dateVar = 50\n",
        "\n",
        "prompt_multi = f\"\"\"\n",
        "                Using the context below as a template, create {multiVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"MULTI-SELECT\". The \"options\" array should contain multiple unique objects,\n",
        "                each with the \"option\" key and a meaningful value representing an available choice. No IDs should be included.\n",
        "                Generate multiple unique examples of questions that make sense in context for the type \"MULTI-SELECT\".\n",
        "                Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Diverse.\n",
        "\n",
        "                Context:\n",
        "                {json_string_multi}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_single = f\"\"\"\n",
        "                Using the context below as a template, create {singleVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"SINGLE-SELECT\". The \"options\" array should contain multiple unique objects,\n",
        "                each with the \"option\" key and a meaningful value representing an available choice. No IDs should be included.\n",
        "                Generate multiple unique examples of questions that make sense in context for the type \"SINGLE-SELECT\".\n",
        "                Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Communications.\n",
        "\n",
        "                Context:\n",
        "                {json_string_single}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_text = f\"\"\"\n",
        "                Using the context below as a template, create {textVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"TEXT\", the \"options\" array always contains exactly one object with\n",
        "                the \"option\" set to \"Text\", and no IDs are included. Generate multiple unique examples of questions that make sense in context\n",
        "                for the type \"TEXT\". They should be open ended. Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Communications. (General topic in the field of communications, not directly the word communications)\n",
        "\n",
        "                Context:\n",
        "                {json_string_text}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_number = f\"\"\"\n",
        "                Using the context below as a template, create {numberVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"NUMBER\", the \"options\" array always contains exactly one object with\n",
        "                the \"option\" set to the category the question best, and no IDs are included. Generate multiple unique examples of questions that make sense in context\n",
        "                for the type \"NUMBER\". Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Convention/Fair.\n",
        "\n",
        "                Context:\n",
        "                {json_string_number}\n",
        "                \"\"\"\n",
        "\n",
        "prompt_date = f\"\"\"\n",
        "                Using the context below as a template, create {dateVar} more JSON objects. The output should include only the keys \"type\",\n",
        "                \"question\", and \"options\". Ensure the \"type\" is always \"DATE\", the \"options\" array always contains exactly one object with\n",
        "                the \"option\" set to \"Date\", and no IDs are included. Generate multiple unique examples of questions that make sense in context\n",
        "                for the type \"DATE\". Make sure the question specifically ask for a date. Add \"Provide a date.\" at the end of each question.\n",
        "                Output only valid JSON, with proper line spacing and indentation, without any additional formatting or code block delimiters.\n",
        "\n",
        "                Topic: Questionnnaire for evaluation. Healthcare.\n",
        "\n",
        "                Context:\n",
        "                {json_string_date}\n",
        "                \"\"\"\n",
        "\n",
        "\n",
        "# responses\n",
        "responses = {\n",
        "    #\"prompt_multi\": \"Questionnaire_Multi_Artificial.json\",\n",
        "    #\"prompt_single\": \"Questionnaire_Single_Artificial.json\",\n",
        "    #\"prompt_date\": \"Questionnaire_Date_Artificial.json\",\n",
        "    #\"prompt_number\": \"Questionnaire_Number_Artificial.json\",\n",
        "    \"prompt_text\": \"Questionnaire_Text_Artificial.json\"\n",
        "}\n",
        "\n",
        "for response_name, response_file in responses.items():\n",
        "    prompt = globals()[response_name]  # Get the prompt string\n",
        "    response = model.generate_content(prompt)  # Get model's response\n",
        "\n",
        "    try:\n",
        "        response_data = json.loads(response.text)  # Parse the response text as JSON\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON for {response_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Write the parsed JSON to a file\n",
        "    with open(response_file, \"w\") as json_file:\n",
        "        json.dump(response_data, json_file, indent=4)\n",
        "\n",
        "    print(f\"JSON file '{response_file}' has been created\")"
      ],
      "metadata": {
        "id": "sxSLA1-SbAG3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#JSON to Dataframe"
      ],
      "metadata": {
        "id": "xoc_3zsxUd6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MULTI"
      ],
      "metadata": {
        "id": "1E1TXueCdKw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_Diverse.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_HeavyIndustry.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_Sales.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/MULTI/Questionnaire_Multi_Artificial_SoftwareDev.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_MULTI = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_MULTI.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('MULTI_combined.csv', index=False)\n",
        "\n",
        "df_MULTI"
      ],
      "metadata": {
        "id": "harKmP4IUdgZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SINGLE"
      ],
      "metadata": {
        "id": "fF6N95AP2eJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_ArtIndustry.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_Communications.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_Diverse.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/main/artificial_questionnaire/SINGLE/Questionnaire_Single_Artificial_SoftwareDev.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_SINGLE = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_SINGLE.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('SINGLE_combined.csv', index=False)\n",
        "\n",
        "df_SINGLE\n"
      ],
      "metadata": {
        "id": "9fA2yR_k2f2Y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NUMBER"
      ],
      "metadata": {
        "id": "_PF7TsoUGzVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_BusinessAndJob.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_HeavyIndustries.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_Diverse.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/NUMBER/Questionnaire_Number_Artificial_Customer.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_NUMBER = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_NUMBER.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('NUMBER_combined.csv', index=False)\n",
        "\n",
        "df_NUMBER"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ymm1w1W-FLfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATE"
      ],
      "metadata": {
        "id": "fknbAzNquMPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_Customer.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_HeavyIndustries.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_Technology.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/DATE/Questionnaire_Date_Artificial_Healthcare.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_DATE = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_DATE.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('DATE_combined.csv', index=False)\n",
        "\n",
        "df_DATE"
      ],
      "metadata": {
        "id": "pOMExV7LuSKa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT"
      ],
      "metadata": {
        "id": "7HtP3UXQa6zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "#Load the JSON data\n",
        "\n",
        "questions = [\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_Communications.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_HeavyIndustries.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_CustomerSupport.json',\n",
        "    'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_questionnaire/TEXT/Questionnaire_Text_Artificial_Convention.json'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for question in questions:\n",
        "    response = requests.get(question)\n",
        "    data = response.json()\n",
        "\n",
        "    #Create a DataFrame from the JSON data\n",
        "\n",
        "    df_temp = pd.DataFrame(data)\n",
        "    df_temp['options'] = df_temp['options'].apply(lambda x: [item['option'] for item in x])\n",
        "    dfs.append(df_temp)\n",
        "\n",
        "df_TEXT = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df_for_csv = df_TEXT.copy()\n",
        "df_for_csv['options'] = df_for_csv['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv.to_csv('TEXT_combined.csv', index=False)\n",
        "\n",
        "df_TEXT"
      ],
      "metadata": {
        "id": "PuXWkq5Ga8nr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer Generation"
      ],
      "metadata": {
        "id": "jYs5pcRiHA45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MULTI"
      ],
      "metadata": {
        "id": "IJu2V5dNOlMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_MULTI_with_answers = df_MULTI.iloc[100:190].copy()\n",
        "\n",
        "# Generate a single compact prompt for all variations\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {', '.join(row['options'])}\n",
        "\n",
        "            Provide 5 different responses to this multiple choice question. Each response should select from the given options. Chose a different\n",
        "            cobination of options (or single option) for each response. Each answer (V, C, Q, E, A) is to be given by a seperate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain the options corresponding to the response.\n",
        "            Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [options corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [options corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [options corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [options corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [options corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "# Parse the response text into separate variations\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Extract each response type\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            # Find the line starting with this prefix\n",
        "            response_line = next((line for line in lines if line.strip().startswith(prefix)), '')\n",
        "            # Remove the prefix and trim\n",
        "            response = response_line.replace(prefix, '', 1).strip()\n",
        "            answers[f\"answer_{key}\"] = response if response else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "            answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "# Process a single row with retries\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "# Process the dataframe\n",
        "answer_columns = df_MULTI_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "# Add columns to dataframe\n",
        "for key in prefixes:\n",
        "    df_MULTI_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "# Save to CSV\n",
        "df_for_csv_MULTI_answer = df_MULTI_with_answers.copy()\n",
        "df_for_csv_MULTI_answer['options'] = df_for_csv_MULTI_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_MULTI_answer.to_csv('MULTI_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_MULTI_with_answers"
      ],
      "metadata": {
        "id": "7HnQEYdTcWJl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0_100 = pd.read_csv('MULTI_answer_combined_0-100.csv', sep = '>')\n",
        "df_101_189 = pd.read_csv('MULTI_answer_combined_101-189.csv', sep = '>')\n",
        "\n",
        "df_MULTI_with_answers_total = pd.concat([df_0_100, df_101_189], ignore_index=True)\n",
        "df_MULTI_with_answers_total.to_csv('MULTI_answer_combined_total.csv', index=False, sep='>')\n"
      ],
      "metadata": {
        "id": "sZGCWwgNPZ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_MULTI_with_answers_total.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_MULTI = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_MULTI.to_csv('MULTI_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_MULTI\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hmW2i6BgUohp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SINGLE"
      ],
      "metadata": {
        "id": "EjMmZuD9gntG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_SINGLE_with_answers = df_SINGLE.iloc[101:150].copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {', '.join(row['options'])}\n",
        "            Provide 5 different responses to this single choice question. Each response should select from the given options. Chose a different\n",
        "            option for each response (if enough options exist for all 5 responses, otherwise repeat options after having already used all of them).\n",
        "            Each answer (V, C, Q, E, A) is to be given by a seperate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain the option corresponding to the response. Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [option corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [option corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [option corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [option corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [option corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_SINGLE_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "# Add columns to dataframe\n",
        "for key in prefixes:\n",
        "    df_SINGLE_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_SINGLE_answer = df_SINGLE_with_answers.copy()\n",
        "df_for_csv_SINGLE_answer['options'] = df_for_csv_SINGLE_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_SINGLE_answer.to_csv('SINGLE_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_SINGLE_with_answers"
      ],
      "metadata": {
        "id": "1lfnfIlMKer7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_0_100 = pd.read_csv('SINGLE_answer_combined_0-100.csv', sep = '>')\n",
        "df_101_189 = pd.read_csv('SINGLE_answer_combined_101-149.csv', sep = '>')\n",
        "\n",
        "df_SINGLE_with_answers_total = pd.concat([df_0_100, df_101_189], ignore_index=True)\n",
        "df_SINGLE_with_answers_total.to_csv('SINGLE_answer_combined_total.csv', index=False, sep='>')"
      ],
      "metadata": {
        "id": "GHnb9QaWWIj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_SINGLE_with_answers_total.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_SINGLE = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_SINGLE.to_csv('SINGLE_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_SINGLE"
      ],
      "metadata": {
        "collapsed": true,
        "id": "58o5474EWVXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NUMBER"
      ],
      "metadata": {
        "id": "0ise3ICagtyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_NUMBER_with_answers = df_NUMBER.copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {row['options']}\n",
        "            Provide 5 different responses to this single choice question, which asks for a number. The question provides a single option defining the type of number to be chosen.\n",
        "            Each response should adhere to the given type but provide a unique answer. Some answers should be written as numbers, some such that the numbers are spelled out.\n",
        "            Each answer (V, C, Q, E, A) is to be given by a separate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain just the number (with correct units) corresponding to the response. Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [number corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [number corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [number corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [number corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [number corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_NUMBER_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "for key in prefixes:\n",
        "    df_NUMBER_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_NUMBER_answer = df_NUMBER_with_answers.copy()\n",
        "df_for_csv_NUMBER_answer['options'] = df_for_csv_NUMBER_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_NUMBER_answer.to_csv('NUMBER_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_NUMBER_with_answers"
      ],
      "metadata": {
        "id": "aU9ROXGkgtcP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert options to strings before melting\n",
        "df_NUMBER_with_answers['options'] = df_NUMBER_with_answers['options'].astype(str)\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_NUMBER_with_answers.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_NUMBER = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_NUMBER.to_csv('NUMBER_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_NUMBER"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rYk5P-mpdlb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATE"
      ],
      "metadata": {
        "id": "ECZEWIdvu1c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_DATE_with_answers = df_DATE.copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {row['options']}\n",
        "            Provide 5 different responses to this single choice question, which asks for a date. The question provides one option defining the type to be chosen.\n",
        "            Each response should adhere to the given type but provide a unique answer. Some answers should be written as numbers, some such that the numbers are spelled out. Use different date formats.\n",
        "            Assume question takers are from Europe.\n",
        "            Each answer (V, C, Q, E, A) is to be given by a separate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain just the date corresponding to the response. Use this date format: dd-mm-yyyy and nothing else for the label.\n",
        "            Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [date corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [date corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [date corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [date corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [date corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_DATE_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "for key in prefixes:\n",
        "    df_DATE_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_DATE_answer = df_DATE_with_answers.copy()\n",
        "df_for_csv_DATE_answer['options'] = df_for_csv_DATE_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_DATE_answer.to_csv('DATE_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_DATE_with_answers"
      ],
      "metadata": {
        "id": "iXfSbksBu5ZP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert options to strings before melting\n",
        "df_DATE_with_answers['options'] = df_DATE_with_answers['options'].astype(str)\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_DATE_with_answers.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_DATE = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_DATE.to_csv('DATE_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_DATE"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sdK6AoV2kX6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEXT"
      ],
      "metadata": {
        "id": "eo-6wzxObq_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.api_core import exceptions\n",
        "\n",
        "df_TEXT_with_answers = df_TEXT.copy()\n",
        "\n",
        "def generate_minimal_prompt(row):\n",
        "    return f\"\"\"Question: {row['question']}\n",
        "            Options: {row['options']}\n",
        "            Provide 5 different responses to this single choice question, which asks for a text. The question provides a single option defining the type of answer to be chosen.\n",
        "            Each response should adhere to the given type but provide a unique answer. The questions are open ended, therfore your answer should replicate a human's answer to such a question.\n",
        "            Each answer (V, C, Q, E, A) is to be given by a separate person.\n",
        "            Each label (V_Sel, C_Sel, Q_Sel, E_Sel, A_Sel) should contain the shortest possible topic summery.\n",
        "            Format exactly as follows:\n",
        "            V: [verbose response, not exceeding 3 sentences]\n",
        "            V_Sel: [summery corresponding to the response V]\n",
        "            C: [concise response]\n",
        "            C_Sel: [summery corresponding to the response C]\n",
        "            Q: [colloquial response, no 'honestly']\n",
        "            Q_Sel: [summery corresponding to the response Q]\n",
        "            E: [explanatory response, not exceeding 3 sentences]\n",
        "            E_Sel: [summery corresponding to the response E]\n",
        "            A: [mildly annoyed response, no 'ugh']\n",
        "            A_Sel: [summery corresponding to the response A]\"\"\"\n",
        "\n",
        "# Define the prefixes for each response type\n",
        "prefixes = {\n",
        "    'verbose': 'V:',\n",
        "    'verbose_Gemini_label': 'V_Sel: ',\n",
        "    'concise': 'C:',\n",
        "    'concise_Gemini_label': 'C_Sel: ',\n",
        "    'colloquial': 'Q:',\n",
        "    'colloquial_Gemini_label': 'Q_Sel: ',\n",
        "    'explanatory': 'E:',\n",
        "    'explanatory_Gemini_label': 'E_Sel: ',\n",
        "    'annoyed': 'A:',\n",
        "    'annoyed_Gemini_label': 'A_Sel: '\n",
        "}\n",
        "\n",
        "def parse_responses(text):\n",
        "    answers = {}\n",
        "    lines = text.split('\\n')\n",
        "    for key, prefix in prefixes.items():\n",
        "        try:\n",
        "            for line in lines:\n",
        "                if line.startswith(prefix):\n",
        "                    line = line.removeprefix(prefix)\n",
        "                    answers[f\"answer_{key}\"] = line if line else f\"Error: No {key} response found\"\n",
        "        except Exception as e:\n",
        "                answers[f\"answer_{key}\"] = f\"Error parsing {key} response: {str(e)}\"\n",
        "\n",
        "    return answers\n",
        "\n",
        "def process_row(row):\n",
        "    prompt = generate_minimal_prompt(row)\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            answers = parse_responses(response.text)\n",
        "            time.sleep(3)\n",
        "            return answers\n",
        "        except exceptions.TooManyRequests:\n",
        "            if attempt < 2:\n",
        "                time.sleep(2 ** attempt)\n",
        "            else:\n",
        "                return {f\"answer_{key}\": \"Error: Rate limit exceeded.\"\n",
        "                       for key in prefixes}\n",
        "        except Exception as e:\n",
        "            print(f\"Generated text was:\\n{response.text}\\n\")  # Print the response text\n",
        "            print(f\"Error: {str(e)}\")\n",
        "            return {f\"answer_{key}\": f\"Error: {str(e)}\"\n",
        "                  for key in prefixes}\n",
        "\n",
        "answer_columns = df_TEXT_with_answers.apply(process_row, axis=1)\n",
        "\n",
        "for key in prefixes:\n",
        "    df_TEXT_with_answers[f\"answer_{key}\"] = answer_columns.apply(lambda x: x[f\"answer_{key}\"])\n",
        "\n",
        "df_for_csv_TEXT_answer = df_TEXT_with_answers.copy()\n",
        "df_for_csv_TEXT_answer['options'] = df_for_csv_TEXT_answer['options'].apply(lambda x: '; '.join(x))\n",
        "df_for_csv_TEXT_answer.to_csv('TEXT_answer_combined.csv', index=False, sep='>')\n",
        "\n",
        "df_TEXT_with_answers"
      ],
      "metadata": {
        "id": "gHv02WL_bsZ7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert options to strings before melting\n",
        "df_TEXT_with_answers['options'] = df_TEXT_with_answers['options'].astype(str)\n",
        "\n",
        "# Step 1: Melt the dataframe to combine all answer columns into one column\n",
        "df_long = df_TEXT_with_answers.melt(\n",
        "    id_vars=[\"type\", \"question\", \"options\"],\n",
        "    var_name=\"answer_type\",\n",
        "    value_name=\"answer_value\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Create a new column for the answer type (e.g., verbose, concise, etc.)\n",
        "df_long[\"answer_category\"] = df_long[\"answer_type\"].str.extract(r\"answer_(\\w+)\")\n",
        "\n",
        "# Step 3: Separate rows into answers and their labels\n",
        "answers = df_long[~df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "labels = df_long[df_long[\"answer_type\"].str.endswith(\"_Gemini_label\")].copy()\n",
        "\n",
        "# Step 4: Add a matching key column to facilitate merging\n",
        "answers[\"label_type\"] = answers[\"answer_type\"] + \"_Gemini_label\"\n",
        "\n",
        "# Step 5: Merge answers with their corresponding labels\n",
        "df_reshaped = pd.merge(\n",
        "    answers,\n",
        "    labels,\n",
        "    left_on=[\"type\", \"question\", \"options\", \"label_type\"],\n",
        "    right_on=[\"type\", \"question\", \"options\", \"answer_type\"],\n",
        "    suffixes=(\"\", \"_label\")\n",
        ")\n",
        "\n",
        "# Step 6: Rename columns and keep the desired ones\n",
        "df_reshaped = df_reshaped.rename(\n",
        "    columns={\"answer_value\": \"answer\", \"answer_value_label\": \"answer_label_GEMINI\"}\n",
        ")[[\"type\", \"question\", \"options\", \"answer\", \"answer_label_GEMINI\", \"answer_category\"]]\n",
        "\n",
        "# Step 7: Sort the data if needed (optional)\n",
        "df_reshaped_TEXT = df_reshaped.sort_values(by=[\"type\", \"question\"]).reset_index(drop=True)\n",
        "\n",
        "# Display the final dataframe\n",
        "df_reshaped_TEXT.to_csv('TEXT_answer_combined_total_reshaped.csv', index=False, sep='>')\n",
        "df_reshaped_TEXT"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8oh-H7Ppkjy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge all CSV Files"
      ],
      "metadata": {
        "id": "fpllBNgP4lnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# list all csv files only\n",
        "csv_files = ['TEXT_answer_combined_total_reshaped.csv', 'DATE_answer_combined_total_reshaped.csv', 'NUMBER_answer_combined_total_reshaped.csv', 'SINGLE_answer_combined_total_reshaped.csv', 'MULTI_answer_combined_total_reshaped.csv']\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create an empty list to store each DataFrame\n",
        "dfs = []\n",
        "\n",
        "# Read each CSV file and append to the list\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file, sep='>')\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV\n",
        "merged_df.to_csv('all_answers_combined_reshaped.csv', index=False, sep='>')\n"
      ],
      "metadata": {
        "id": "3gPayKx5r-MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv('all_answers_combined_reshaped.csv', sep='>')\n",
        "df_all"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EL7_TQMzsorm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['options'] = df_all['options'].str.replace(r\"\\['|'\\]\", \"\", regex=True)"
      ],
      "metadata": {
        "id": "uR_rbnNdvV18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.to_csv('all_answers_combined_reshaped.csv', index=False, sep='>')"
      ],
      "metadata": {
        "id": "86ZLZ9PYvgg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Up CSV"
      ],
      "metadata": {
        "id": "27qOi2nti_bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all rows containing quotation marks\n",
        "\n",
        "import csv\n",
        "import requests\n",
        "\n",
        "def clean_csv_from_github(url, output_file):\n",
        "    \"\"\"\n",
        "    Reads a CSV file from a GitHub raw URL, removes rows containing quotation marks,\n",
        "    and saves the cleaned data to a new CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): The GitHub raw URL of the CSV file.\n",
        "        output_file (str): The file path to save the cleaned CSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fetch the CSV content from the GitHub raw URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "\n",
        "        # Decode the content and split into lines\n",
        "        csv_content = response.text\n",
        "        csv_lines = csv_content.splitlines()\n",
        "\n",
        "        # Read the CSV into memory\n",
        "        reader = csv.reader(csv_lines, delimiter='>')\n",
        "        cleaned_rows = []\n",
        "\n",
        "        for row in reader:\n",
        "            # Remove rows containing quotation marks\n",
        "            if not any('\"' in field for field in row):\n",
        "                cleaned_rows.append(row)\n",
        "\n",
        "        # Write the cleaned rows to a new CSV file\n",
        "        with open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
        "            writer = csv.writer(outfile, delimiter='>')\n",
        "            writer.writerows(cleaned_rows)\n",
        "\n",
        "        print(f\"Cleaned CSV saved to {output_file}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching the CSV file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_answers/all_answers_combined_reshaped.csv'\n",
        "output_file = 'cleaned_all_answers_combined_reshaped.csv'\n",
        "clean_csv_from_github(url, output_file)"
      ],
      "metadata": {
        "id": "YyZdvoVCjDsc",
        "outputId": "bc231184-056f-470f-acd8-d2d0be92e76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned CSV saved to cleaned_all_answers_combined_reshaped.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes"
      ],
      "metadata": {
        "id": "G8MTiEvrki5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "\n",
        "def load_csv_method1(url):\n",
        "    df = pd.read_csv(url, sep='>', names=['type', 'question', 'options', 'answer', 'answer_label_GEMINI', 'answer_category'], converters={'options': lambda x: x.split(';')})\n",
        "    return df\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Penguinbeanie/Capstone-Project/refs/heads/dev_branch/artificial_answers/MULTI/MULTI_answer_combined_total_reshaped.csv'\n",
        "df_full = load_csv_method1(url)\n",
        "\n",
        "df_test = df_full.copy().head(10)\n",
        "\n",
        "# Function to classify each row\n",
        "def classify_row(row):\n",
        "    result = classifier(row[\"answer\"], candidate_labels=row[\"options\"], multi_label=True)\n",
        "    result_list = list(zip(result[\"labels\"], result[\"scores\"]))\n",
        "    filtered_list = [label for label, score in result_list if score > 0.5]\n",
        "    print(filtered_list)\n",
        "\n",
        "    return filtered_list\n",
        "\n",
        "\n",
        "# Apply the classification to each row\n",
        "\n",
        "df_test[\"predicted_options\"] = df_test.apply(lambda row: classify_row(row), axis=1)\n",
        "\n",
        "# Display the DataFrame\n",
        "df_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "XhfwJ2apV3X8",
        "outputId": "939d5755-9c62-4611-ba3e-87ea364b02de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[' Searching algorithms', ' Graph algorithms', 'Sorting algorithms']\n",
            "[' Graph algorithms', ' Searching algorithms', 'Sorting algorithms']\n",
            "[' Dynamic programming', ' Searching algorithms', 'Sorting algorithms', ' Graph algorithms']\n",
            "[' Greedy algorithms', ' Searching algorithms', 'Sorting algorithms', ' Dynamic programming']\n",
            "[' Divide and conquer', 'Sorting algorithms', ' Searching algorithms']\n",
            "[' Technology changes', 'Competition', ' Economic conditions']\n",
            "['Competition', ' Finding and retaining talent']\n",
            "[' Economic conditions', ' Finding and retaining talent', 'Competition']\n",
            "[' Technology changes', ' Regulations']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           type                                           question  \\\n",
              "0          type                                           question   \n",
              "1  MULTI-SELECT             What algorithms are you familiar with?   \n",
              "2  MULTI-SELECT             What algorithms are you familiar with?   \n",
              "3  MULTI-SELECT             What algorithms are you familiar with?   \n",
              "4  MULTI-SELECT             What algorithms are you familiar with?   \n",
              "5  MULTI-SELECT             What algorithms are you familiar with?   \n",
              "6  MULTI-SELECT  What are some of the key challenges facing you...   \n",
              "7  MULTI-SELECT  What are some of the key challenges facing you...   \n",
              "8  MULTI-SELECT  What are some of the key challenges facing you...   \n",
              "9  MULTI-SELECT  What are some of the key challenges facing you...   \n",
              "\n",
              "                                             options  \\\n",
              "0                                          [options]   \n",
              "1  [Sorting algorithms,  Searching algorithms,  G...   \n",
              "2  [Sorting algorithms,  Searching algorithms,  G...   \n",
              "3  [Sorting algorithms,  Searching algorithms,  G...   \n",
              "4  [Sorting algorithms,  Searching algorithms,  G...   \n",
              "5  [Sorting algorithms,  Searching algorithms,  G...   \n",
              "6  [Competition,  Economic conditions,  Technolog...   \n",
              "7  [Competition,  Economic conditions,  Technolog...   \n",
              "8  [Competition,  Economic conditions,  Technolog...   \n",
              "9  [Competition,  Economic conditions,  Technolog...   \n",
              "\n",
              "                                              answer  \\\n",
              "0                                             answer   \n",
              "1  I'm familiar with a wide range of algorithms, ...   \n",
              "2          Sorting, searching, and graph algorithms.   \n",
              "3  I know a bunch of those, like the sorting and ...   \n",
              "4  My algorithm knowledge encompasses several cat...   \n",
              "5  I know about sorting, searching, and divide an...   \n",
              "6  Our biggest hurdle is definitely keeping up wi...   \n",
              "7          Competition and finding/retaining talent.   \n",
              "8  It's a tough market, right?  The economy's kin...   \n",
              "9  The current regulatory landscape presents sign...   \n",
              "\n",
              "                                 answer_label_GEMINI  answer_category  \\\n",
              "0                                answer_label_GEMINI  answer_category   \n",
              "1  [Sorting algorithms, Searching algorithms, Gra...          verbose   \n",
              "2  [Sorting algorithms, Searching algorithms, Gra...          concise   \n",
              "3  [Sorting algorithms, Searching algorithms, Gra...       colloquial   \n",
              "4  [Sorting algorithms, Searching algorithms, Dyn...      explanatory   \n",
              "5  [Sorting algorithms, Searching algorithms, Div...          annoyed   \n",
              "6  Technology changes, Competition, Economic cond...          verbose   \n",
              "7          Competition, Finding and retaining talent          concise   \n",
              "8  Economic conditions, Finding and retaining tal...       colloquial   \n",
              "9                    Regulations, Technology changes      explanatory   \n",
              "\n",
              "                                   predicted_options  \n",
              "0                                                 []  \n",
              "1  [ Searching algorithms,  Graph algorithms, Sor...  \n",
              "2  [ Graph algorithms,  Searching algorithms, Sor...  \n",
              "3  [ Dynamic programming,  Searching algorithms, ...  \n",
              "4  [ Greedy algorithms,  Searching algorithms, So...  \n",
              "5  [ Divide and conquer, Sorting algorithms,  Sea...  \n",
              "6  [ Technology changes, Competition,  Economic c...  \n",
              "7       [Competition,  Finding and retaining talent]  \n",
              "8  [ Economic conditions,  Finding and retaining ...  \n",
              "9                [ Technology changes,  Regulations]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1a712af-c12b-4aa7-94ee-9144943c3714\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>question</th>\n",
              "      <th>options</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_label_GEMINI</th>\n",
              "      <th>answer_category</th>\n",
              "      <th>predicted_options</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>type</td>\n",
              "      <td>question</td>\n",
              "      <td>[options]</td>\n",
              "      <td>answer</td>\n",
              "      <td>answer_label_GEMINI</td>\n",
              "      <td>answer_category</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What algorithms are you familiar with?</td>\n",
              "      <td>[Sorting algorithms,  Searching algorithms,  G...</td>\n",
              "      <td>I'm familiar with a wide range of algorithms, ...</td>\n",
              "      <td>[Sorting algorithms, Searching algorithms, Gra...</td>\n",
              "      <td>verbose</td>\n",
              "      <td>[ Searching algorithms,  Graph algorithms, Sor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What algorithms are you familiar with?</td>\n",
              "      <td>[Sorting algorithms,  Searching algorithms,  G...</td>\n",
              "      <td>Sorting, searching, and graph algorithms.</td>\n",
              "      <td>[Sorting algorithms, Searching algorithms, Gra...</td>\n",
              "      <td>concise</td>\n",
              "      <td>[ Graph algorithms,  Searching algorithms, Sor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What algorithms are you familiar with?</td>\n",
              "      <td>[Sorting algorithms,  Searching algorithms,  G...</td>\n",
              "      <td>I know a bunch of those, like the sorting and ...</td>\n",
              "      <td>[Sorting algorithms, Searching algorithms, Gra...</td>\n",
              "      <td>colloquial</td>\n",
              "      <td>[ Dynamic programming,  Searching algorithms, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What algorithms are you familiar with?</td>\n",
              "      <td>[Sorting algorithms,  Searching algorithms,  G...</td>\n",
              "      <td>My algorithm knowledge encompasses several cat...</td>\n",
              "      <td>[Sorting algorithms, Searching algorithms, Dyn...</td>\n",
              "      <td>explanatory</td>\n",
              "      <td>[ Greedy algorithms,  Searching algorithms, So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What algorithms are you familiar with?</td>\n",
              "      <td>[Sorting algorithms,  Searching algorithms,  G...</td>\n",
              "      <td>I know about sorting, searching, and divide an...</td>\n",
              "      <td>[Sorting algorithms, Searching algorithms, Div...</td>\n",
              "      <td>annoyed</td>\n",
              "      <td>[ Divide and conquer, Sorting algorithms,  Sea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What are some of the key challenges facing you...</td>\n",
              "      <td>[Competition,  Economic conditions,  Technolog...</td>\n",
              "      <td>Our biggest hurdle is definitely keeping up wi...</td>\n",
              "      <td>Technology changes, Competition, Economic cond...</td>\n",
              "      <td>verbose</td>\n",
              "      <td>[ Technology changes, Competition,  Economic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What are some of the key challenges facing you...</td>\n",
              "      <td>[Competition,  Economic conditions,  Technolog...</td>\n",
              "      <td>Competition and finding/retaining talent.</td>\n",
              "      <td>Competition, Finding and retaining talent</td>\n",
              "      <td>concise</td>\n",
              "      <td>[Competition,  Finding and retaining talent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What are some of the key challenges facing you...</td>\n",
              "      <td>[Competition,  Economic conditions,  Technolog...</td>\n",
              "      <td>It's a tough market, right?  The economy's kin...</td>\n",
              "      <td>Economic conditions, Finding and retaining tal...</td>\n",
              "      <td>colloquial</td>\n",
              "      <td>[ Economic conditions,  Finding and retaining ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MULTI-SELECT</td>\n",
              "      <td>What are some of the key challenges facing you...</td>\n",
              "      <td>[Competition,  Economic conditions,  Technolog...</td>\n",
              "      <td>The current regulatory landscape presents sign...</td>\n",
              "      <td>Regulations, Technology changes</td>\n",
              "      <td>explanatory</td>\n",
              "      <td>[ Technology changes,  Regulations]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1a712af-c12b-4aa7-94ee-9144943c3714')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1a712af-c12b-4aa7-94ee-9144943c3714 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1a712af-c12b-4aa7-94ee-9144943c3714');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbd6d41f-1353-42f5-88d8-7060bc4de25b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbd6d41f-1353-42f5-88d8-7060bc4de25b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbd6d41f-1353-42f5-88d8-7060bc4de25b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4116744b-6401-4a08-85ef-9a3b058a261f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4116744b-6401-4a08-85ef-9a3b058a261f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"MULTI-SELECT\",\n          \"type\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"question\",\n          \"What algorithms are you familiar with?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"options\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"It's a tough market, right?  The economy's kinda wobbly, and  finding good people is a nightmare! Plus, the competition is fierce.\",\n          \"I'm familiar with a wide range of algorithms, including sorting algorithms like merge sort and quicksort, and searching algorithms such as binary search and breadth-first search.  My knowledge also extends to graph algorithms.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_label_GEMINI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Economic conditions, Finding and retaining talent, Competition\",\n          \"[Sorting algorithms, Searching algorithms, Graph algorithms]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"answer_category\",\n          \"verbose\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_options\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5RD5IZEdCkjI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}